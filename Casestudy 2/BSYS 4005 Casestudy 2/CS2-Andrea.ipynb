{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Import necessary modules\n",
    "\n",
    "# pandas is used for reading, grouping, and aggregating data\n",
    "import pandas as pd\n",
    "\n",
    "# numpy is used for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# gradient boosting model for forecasting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# RMSE calculation (used for validation)\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "# Step 2. Load input file and output template\n",
    "\n",
    "# input file created from Case Study #1 parsing\n",
    "INPUT_FILE = \"1CS2_HistoryData.csv\"\n",
    "\n",
    "# output template provided by instructor\n",
    "OUTPUT_TEMPLATE = \"1CS2-ExampleOutput.csv\"\n",
    "\n",
    "# read the parsed transaction-level data\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# convert Date column to datetime for time-series operations\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Step 3. Aggregate transaction-level data to daily totals\n",
    "\n",
    "# group by Date and sum Amounts to get daily transaction volume\n",
    "daily_df = (\n",
    "    df.groupby('Date')['Amount']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# rename column to be explicit\n",
    "daily_df.rename(columns={'Amount': 'Transactions'}, inplace=True)\n",
    "\n",
    "# sort by date to preserve time order\n",
    "daily_df = daily_df.sort_values('Date')\n",
    "\n",
    "# set Date as index for forecasting\n",
    "daily_df.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "# Step 4. Train / test split (time-based)\n",
    "\n",
    "# determine last available date in the dataset\n",
    "last_date = daily_df.index.max()\n",
    "\n",
    "# use final 20% of data as test set\n",
    "split_date = daily_df.index[int(len(daily_df) * 0.8)]\n",
    "\n",
    "# training data (first 80%)\n",
    "train = daily_df[daily_df.index < split_date]\n",
    "\n",
    "# testing data (last 20%)\n",
    "test = daily_df[daily_df.index >= split_date]\n",
    "\n",
    "print(\"Training rows:\", len(train))\n",
    "print(\"Testing rows:\", len(test))\n",
    "\n",
    "\n",
    "# Step 5. Baseline (naive) model\n",
    "\n",
    "# naive forecast: previous day's value\n",
    "naive_predictions = test['Transactions'].shift(1)\n",
    "\n",
    "# drop rows where prediction is missing\n",
    "valid_idx = naive_predictions.notna()\n",
    "\n",
    "# calculate RMSE only if data exists\n",
    "if valid_idx.sum() > 0:\n",
    "    naive_rmse = root_mean_squared_error(\n",
    "        test.loc[valid_idx, 'Transactions'],\n",
    "        naive_predictions.loc[valid_idx]\n",
    "    )\n",
    "    print(\"Naive RMSE:\", naive_rmse)\n",
    "else:\n",
    "    print(\"Naive RMSE could not be calculated (insufficient test data)\")\n",
    "\n",
    "\n",
    "\n",
    "# Step 6. Feature engineering function\n",
    "\n",
    "def create_features(data):\n",
    "    \"\"\"\n",
    "    Creates lag, rolling average, and calendar features\n",
    "    to capture transaction time patterns.\n",
    "    \"\"\"\n",
    "\n",
    "    df_feat = data.copy()\n",
    "\n",
    "    # lagged transaction values\n",
    "    df_feat['lag_1'] = df_feat['Transactions'].shift(1)\n",
    "    df_feat['lag_7'] = df_feat['Transactions'].shift(7)\n",
    "    df_feat['lag_14'] = df_feat['Transactions'].shift(14)\n",
    "\n",
    "    # rolling averages smooth noise\n",
    "    df_feat['rolling_7'] = df_feat['Transactions'].rolling(7).mean()\n",
    "    df_feat['rolling_14'] = df_feat['Transactions'].rolling(14).mean()\n",
    "\n",
    "    # calendar-based features\n",
    "    df_feat['day_of_week'] = df_feat.index.dayofweek\n",
    "    df_feat['month'] = df_feat.index.month\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "# Step 7. Prepare data for machine learning\n",
    "\n",
    "# apply feature engineering\n",
    "feature_df = create_features(daily_df)\n",
    "\n",
    "# drop rows with missing values caused by lagging\n",
    "feature_df = feature_df.dropna()\n",
    "\n",
    "# determine split date again after feature engineering\n",
    "split_date_feat = feature_df.index[int(len(feature_df) * 0.8)]\n",
    "\n",
    "# split engineered data\n",
    "train_feat = feature_df[feature_df.index < split_date_feat]\n",
    "test_feat = feature_df[feature_df.index >= split_date_feat]\n",
    "\n",
    "# separate predictors and target\n",
    "X_train = train_feat.drop('Transactions', axis=1)\n",
    "y_train = train_feat['Transactions']\n",
    "\n",
    "X_test = test_feat.drop('Transactions', axis=1)\n",
    "y_test = test_feat['Transactions']\n",
    "\n",
    "\n",
    "\n",
    "# Step 8. Train Gradient Boosting model\n",
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# generate predictions for test set\n",
    "gb_predictions = model.predict(X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "gb_rmse = root_mean_squared_error(\n",
    "    y_test,\n",
    "    gb_predictions\n",
    ")\n",
    "\n",
    "print(\"Gradient Boosting RMSE:\", gb_rmse)\n",
    "\n",
    "\n",
    "# Step 9. Train final model on ALL historical data\n",
    "\n",
    "X_full = feature_df.drop('Transactions', axis=1)\n",
    "y_full = feature_df['Transactions']\n",
    "\n",
    "final_model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "# Step 10. Generate future forecast dates\n",
    "\n",
    "# define forecast start date (day after last historical date)\n",
    "forecast_start = daily_df.index.max() + pd.Timedelta(days=1)\n",
    "\n",
    "# number of days to forecast (must match assignment requirements)\n",
    "FORECAST_DAYS = 90   # change if instructor specifies different length\n",
    "\n",
    "# generate a date range for the forecast horizon\n",
    "forecast_dates = pd.date_range(\n",
    "    start=forecast_start,\n",
    "    periods=FORECAST_DAYS,\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "# copy historical data so lag features work correctly\n",
    "history = daily_df.copy()\n",
    "\n",
    "# list to store predicted values\n",
    "future_predictions = []\n",
    "\n",
    "# loop through each forecast date\n",
    "for date in forecast_dates:\n",
    "\n",
    "    # create features using the most recent data\n",
    "    latest_features = create_features(history).iloc[-1:]\n",
    "    X_future = latest_features.drop('Transactions', axis=1)\n",
    "\n",
    "    # predict next day's transactions\n",
    "    prediction = final_model.predict(X_future)[0]\n",
    "    future_predictions.append(prediction)\n",
    "\n",
    "    # append prediction to history for next iteration\n",
    "    history.loc[date] = prediction\n",
    "\n",
    "\n",
    "# Step 11. Write final output file\n",
    "\n",
    "# define group name exactly as required\n",
    "GROUP_NAME = \"Group 1\"\n",
    "\n",
    "# build output dataframe in required column order\n",
    "output_df = pd.DataFrame({\n",
    "    \"Group\": GROUP_NAME,\n",
    "    \"Date\": forecast_dates.strftime(\"%Y-%m-%d\"),\n",
    "    \"Total Predicted Amount\": future_predictions\n",
    "})\n",
    "\n",
    "# save output file\n",
    "output_df.to_csv(\"final_forecast_output.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
